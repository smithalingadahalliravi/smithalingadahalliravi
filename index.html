<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Smitha Lingadahalli Ravi</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Smitha Lingadahalli Ravi" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="https://vishal-keshav.github.io/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Smitha Lingadahalli Ravi
              </h1>
              <p>
                I am a third year doctoral student at Orange Labs and INSA Rennes in France.My primary research interests are in computer vision, deep learning.
              </p>
              <p>
                I obtained my Bachelor's in Electronics and Communication Engineering from Nitte Meenakshi Institute of Technology, India.
              <p style="text-align:center">
                <a href="#post">Posts</a> &nbsp;/&nbsp;
                <a href = "mailto: lingadahalliravismitha@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="https://fr.linkedin.com/in/smitha-lingadahalli-ravi-03760b20a"> LinkedIn </a> &nbsp;/&nbsp;
                <a href="https://www.researchgate.net/profile/Smitha-Lingadahalli-Ravi"> ResearchGate </a> &nbsp;/&nbsp;
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.jpg">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Projects/Papers/Patents</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">


          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/structuring.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Project - Exploring Temporal Consistency in in Image-Based Rendering for Immersive Video Transmission</h3>
              <br>
              
              
              
              
              <a href="/pdfs/camera_ready_paper.pdf">pdf</a> /
              
                     
              
              
              <p></p>
              <p>Abstract: Image-based rendering methods synthesize novel
views given input images captured from multiple viewpoints
to display free viewpoint immersive video. Despite significant
progress with the recent learning-based approaches, there are
still some drawbacks. In particular, these approaches operate
at the still image level and do not maintain consistency among
consecutive time instants, leading to temporal noise. To address
this, we propose an intra-only framework to identify regions of
input images leading to temporally inconsistent synthesized views.
Our method synthesizes better and more stable novel views, even
in the most general use case of immersive video transmission. We
conclude that the network seems to identify and correct spatial
features at the still image level that produce artifacts in the
temporal dimension.</p>

            </td>
          </tr>
              </ul>
            </td>
          </tr>
    
    
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/structuring.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Project - A Study of Conventional and Learning-Based Depth Estimators for Immersive Video Transmission</h3>
              <br>
              
              
              
              
              <a href="/pdfs/Camera_Ready_MMSP.pdf">pdf</a> /
              
                     
              
              
              <p></p>
              <p>Abstract: Obtaining an accurate depth map of a scene is
very important for major applications like immersive video,
robotics, autonomous driving, and many more. The different
methods to estimate depths can be classified as conventional
and learning-based methods. While these methods have been
studied for their depth accuracy, less attention has been paid to
studying their performance in the use case of depth image-based
rendering (DIBR). Here we study and evaluate two conventional
methods and five learning-based methods for a real-world use
case of immersive video transmission in the context of MPEG-I.
The user-requested views are synthesized using Test Model for
Immersive Video (TMIV) from the depth maps obtained by all
methods and original texture views. The synthesized images are
compared with their original counterparts using various quality
metrics.</p>

            </td>
          </tr>
              </ul>
            </td>
          </tr>


          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/structuring.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Project - Overview and Efficiency of Decoder-Side Depth Estimation in MPEG Immersive Video </h3>
              <br>
              
              
              
              
              <a href="/pdfs/Overview_and_Efficiency_of_Decoder-Side_Depth_Estimation_in_MPEG_Immersive_Video.pdf">pdf</a> /
              
                     
              
              
              <p></p>
              <p>Abstract: This paper presents the overview and rationale
behind the Decoder-Side Depth Estimation (DSDE) mode of
the MPEG Immersive Video (MIV) standard, using the
Geometry Absent profile, for efficient compression of
immersive multiview video. A MIV bitstream generated by an
encoder operating in the DSDE mode does not include depth
maps. It only contains the information required to reconstruct
them in the client or in the cloud: decoded views and metadata.
The paper explains the technical details and techniques
supported by this novel MIV DSDE mode. The description
additionally includes the specification on Geometry Assistance
Supplemental Enhancement Information which helps to reduce
the complexity of depth estimation, when performed in the
cloud or at the decoder side. The depth estimation in MIV is a
non-normative part of the decoding process, therefore, any
method can be used to compute the depth maps. This paper lists
a set of requirements for depth estimation, induced by the
specific characteristics of the DSDE. The depth estimation
reference software, continuously and collaboratively developed
with MIV to meet these requirements, is presented in this paper.
Several original experimental results are presented. The
efficiency of the DSDE is compared to two MIV profiles. The
combined non-transmission of depth maps and efficient coding
of textures enabled by the DSDE leads to efficient compression
and rendering quality improvement compared to the usual
encoder-side depth estimation. Moreover, results of the first
evaluation of state-of-the-art multiview depth estimators in the
DSDE context, including machine learning techniques, are
presented.</p>

            </td>
          </tr>
              </ul>
            </td>
          </tr>

        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>		
